<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>P2P Video Call - Filters & Backgrounds</title>
    
    <script src="https://unpkg.com/peerjs@1.5.2/dist/peerjs.min.js"></script>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.2.0"></script>

    <style>
        :root {
            --bg: #121212;
            --panel: #1e1e1e;
            --primary: #4d90fe;
            --danger: #ea4335;
            --text: #ffffff;
            --accent: #bb86fc;
        }

        body {
            font-family: 'Segoe UI', sans-serif;
            background: var(--bg);
            color: var(--text);
            margin: 0;
            height: 100vh;
            display: flex;
            flex-direction: column;
        }

        /* --- HEADER --- */
        .header {
            padding: 15px 20px;
            background: var(--panel);
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 1px solid #333;
        }
        .status { font-size: 14px; color: #888; font-weight: bold; }
        .status.online { color: #2ecc71; }

        /* --- VIDEO AREA --- */
        .video-container {
            flex: 1;
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 20px;
            padding: 20px;
            flex-wrap: wrap;
            position: relative;
        }

        .vid-wrapper {
            position: relative;
            width: 45%;
            min-width: 320px;
            aspect-ratio: 16/9;
            background: #000;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 4px 10px rgba(0,0,0,0.5);
        }

        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            background: #000;
        }

        /* Hidden elements used for processing */
        #hiddenVideo { display: none; } 
        #processingCanvas { display: none; }

        /* Mirror local video */
        #localVideo { transform: scaleX(-1); }

        .label {
            position: absolute;
            bottom: 15px;
            left: 15px;
            background: rgba(0,0,0,0.6);
            padding: 4px 10px;
            border-radius: 4px;
            font-size: 13px;
            pointer-events: none;
            z-index: 10;
        }

        /* --- CONTROLS --- */
        .controls-area {
            background: var(--panel);
            padding: 15px;
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 15px;
            flex-wrap: wrap;
            border-top: 1px solid #333;
        }

        .control-group {
            display: flex;
            gap: 10px;
            background: #2d2d2d;
            padding: 8px;
            border-radius: 8px;
            align-items: center;
        }

        .effects-panel {
            background: #2d2d2d;
            padding: 8px 15px;
            border-radius: 8px;
            display: flex;
            gap: 10px;
            align-items: center;
        }

        select, input[type="text"] {
            background: #3a3a3a;
            border: 1px solid #444;
            color: white;
            padding: 8px;
            border-radius: 5px;
            outline: none;
        }
        
        label { font-size: 12px; color: #aaa; margin-right: 5px; }

        button {
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-weight: 600;
            transition: 0.2s;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 5px;
        }

        .btn-blue { background: var(--primary); color: white; }
        .btn-copy { background: #444; color: white; }
        .btn-end { background: var(--danger); color: white; }
        
        .btn-circle {
            width: 45px;
            height: 45px;
            border-radius: 50%;
            padding: 0;
            background: #3c4043;
            color: white;
            font-size: 20px;
        }
        .btn-circle.off { background: var(--danger); position: relative; }
        .btn-circle.off::after {
            content: ''; position: absolute; width: 2px; height: 20px;
            background: white; transform: rotate(45deg);
        }

        button:hover { opacity: 0.9; transform: scale(1.05); }

        /* Loading Overlay */
        #loader {
            position: absolute;
            top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(0,0,0,0.8);
            color: white;
            padding: 20px;
            border-radius: 8px;
            display: none;
            z-index: 100;
        }

    </style>
</head>
<body>

    <video id="hiddenVideo" autoplay playsinline muted></video>
    <canvas id="processingCanvas"></canvas>

    <div id="loader">Loading AI Model...</div>

    <div class="header">
        <div>白 Secure P2P Call</div>
        <div id="status-text" class="status">Initializing...</div>
    </div>

    <div class="video-container">
        <div class="vid-wrapper">
            <video id="localVideo" autoplay muted playsinline></video>
            <div class="label">You (Filtered)</div>
        </div>
        
        <div class="vid-wrapper">
            <video id="remoteVideo" autoplay playsinline></video>
            <div class="label">Remote User</div>
        </div>
    </div>

    <div class="controls-area">
        
        <div class="control-group">
            <button class="btn-circle" id="btn-mic" onclick="toggleAudio()" title="Toggle Microphone">痔</button>
            <button class="btn-circle" id="btn-cam" onclick="toggleVideo()" title="Toggle Camera">胴</button>
        </div>

        <div class="effects-panel">
            <div>
                <label>Filter:</label>
                <select id="filter-select" onchange="updateEffect()">
                    <option value="none">None</option>
                    <option value="sepia">Sepia</option>
                    <option value="grayscale">B&W</option>
                    <option value="contrast">High Contrast</option>
                    <option value="hue">Alien (Hue)</option>
                </select>
            </div>
            <div>
                <label>Background:</label>
                <select id="bg-select" onchange="updateEffect()">
                    <option value="none">Normal</option>
                    <option value="blur">Blur (AI)</option>
                </select>
            </div>
        </div>

        <div class="control-group" id="connection-controls">
            <input type="text" id="my-id" readonly placeholder="Generating ID..." style="width: 100px;">
            <button class="btn-copy" onclick="copyID()">Copy</button>
        </div>

        <div class="control-group" id="call-input-area">
            <input type="text" id="friend-id" placeholder="Friend ID" style="width: 120px;">
            <button class="btn-blue" onclick="makeCall()">到 Call</button>
        </div>

        <button class="btn-end" id="end-btn" onclick="endCall()" style="display: none;">End Call</button>

    </div>

    <script>
        // UI Elements
        const localVideoDisplay = document.getElementById('localVideo'); // Shows processed stream
        const hiddenVideo = document.getElementById('hiddenVideo'); // Raw camera input
        const processingCanvas = document.getElementById('processingCanvas');
        const ctx = processingCanvas.getContext('2d');
        const remoteVideo = document.getElementById('remoteVideo');
        const statusText = document.getElementById('status-text');
        const myIdInput = document.getElementById('my-id');
        const btnMic = document.getElementById('btn-mic');
        const btnCam = document.getElementById('btn-cam');
        const loader = document.getElementById('loader');

        // State
        let localRawStream = null;    // From Camera
        let processedStream = null;   // From Canvas (Sent to peer)
        let peer = null;
        let currentCall = null;
        let net = null; // BodyPix Model
        let isModelLoaded = false;
        let animationId = null;

        // Settings
        let currentFilter = 'none';
        let currentBg = 'none';

        // 1. Start Camera & Processing Loop
        async function startSystem() {
            try {
                // Get Raw Camera
                localRawStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                
                // Attach raw stream to hidden video for processing
                hiddenVideo.srcObject = localRawStream;
                
                // Wait for video metadata to load to set canvas size
                hiddenVideo.onloadedmetadata = () => {
                    processingCanvas.width = hiddenVideo.videoWidth;
                    processingCanvas.height = hiddenVideo.videoHeight;
                    startProcessingLoop(); // Start the magic
                };

                // Create a stream from the canvas (30 FPS)
                // We extract the video track from canvas, but grab the Audio track from raw stream
                const canvasStream = processingCanvas.captureStream(30);
                const audioTrack = localRawStream.getAudioTracks()[0];
                canvasStream.addTrack(audioTrack); // Add audio to the canvas stream
                
                processedStream = canvasStream;
                localVideoDisplay.srcObject = processedStream; // Show user their filtered self

                initPeer(); // Connect to network
                
                // Preload BodyPix (AI)
                loadBodyPix();

            } catch (err) {
                alert("Camera access denied or error.");
                console.error(err);
            }
        }

        async function loadBodyPix() {
            console.log("Loading AI Model...");
            net = await bodyPix.load({
                architecture: 'MobileNetV1',
                outputStride: 16,
                multiplier: 0.75,
                quantBytes: 2
            });
            isModelLoaded = true;
            console.log("AI Model Loaded");
        }

        // 2. The Processing Loop (Draws frames + Effects)
        async function startProcessingLoop() {
            async function renderFrame() {
                if (!hiddenVideo.paused && !hiddenVideo.ended) {
                    
                    // A. Handle Background Blur (AI)
                    if (currentBg === 'blur' && isModelLoaded) {
                        try {
                            // Segmentation
                            const segmentation = await net.segmentPerson(hiddenVideo, {
                                flipHorizontal: false,
                                internalResolution: 'medium',
                                segmentationThreshold: 0.7
                            });

                            // Draw Blur
                            const backgroundBlurAmount = 10;
                            const edgeBlurAmount = 3;
                            const flipHorizontal = false;

                            bodyPix.drawBokehEffect(
                                processingCanvas, 
                                hiddenVideo, 
                                segmentation, 
                                backgroundBlurAmount, 
                                edgeBlurAmount, 
                                flipHorizontal
                            );

                        } catch (e) { console.error(e); }
                    } else {
                        // Normal Draw (No background effect)
                        ctx.filter = 'none';
                        ctx.drawImage(hiddenVideo, 0, 0, processingCanvas.width, processingCanvas.height);
                    }

                    // B. Handle Color Filters
                    // We apply this ON TOP of whatever is on the canvas (normal or blurred)
                    if (currentFilter !== 'none') {
                        // Note: Context filters apply to the *next* draw operation. 
                        // But since we might have already drawn via BodyPix, we cheat by using GlobalCompositeOperation or just drawing the canvas onto itself with a filter.
                        // Easier way for simple filters:
                        
                        // Save current image
                        const imageData = ctx.getImageData(0,0, processingCanvas.width, processingCanvas.height);
                        
                        // Clear and set filter
                        ctx.clearRect(0,0, processingCanvas.width, processingCanvas.height);
                        
                        let filterString = 'none';
                        if(currentFilter === 'sepia') filterString = 'sepia(1)';
                        if(currentFilter === 'grayscale') filterString = 'grayscale(1)';
                        if(currentFilter === 'contrast') filterString = 'contrast(150%)';
                        if(currentFilter === 'hue') filterString = 'hue-rotate(90deg)';
                        
                        ctx.filter = filterString;
                        
                        // Redraw the image data onto the canvas with the filter active via CreateImageBitmap (async) or just simple drawImage if we had an offscreen canvas.
                        // Simplified approach for performance: Apply filter logic directly to the main draw.
                        // If BodyPix was used, the canvas is filled. We need to re-apply filter.
                        // Actually, ctx.filter works on drawImage.
                        // If we did BodyPix, it's already drawn.
                        
                        if(currentBg !== 'blur') {
                            // If no blur, we redraw video with filter
                            ctx.filter = filterString;
                            ctx.drawImage(hiddenVideo, 0, 0, processingCanvas.width, processingCanvas.height);
                        } else {
                            // If blur IS active, we can't easily filter the result of drawBokehEffect without a second pass.
                            // For this simple demo, we will prioritize Blur over Color filters if both are selected, 
                            // OR we use a second canvas. Let's stick to simple:
                            // CSS Filters on the Canvas Context apply to drawing commands.
                            // BodyPix draws directly to context.
                        }
                    }
                }
                animationId = requestAnimationFrame(renderFrame);
            }
            renderFrame();
        }

        function updateEffect() {
            currentFilter = document.getElementById('filter-select').value;
            currentBg = document.getElementById('bg-select').value;

            if (currentBg === 'blur' && !isModelLoaded) {
                loader.style.display = 'block';
                setTimeout(() => {
                    if(isModelLoaded) loader.style.display = 'none';
                    else { alert("AI Model still loading, please wait..."); loader.style.display = 'none'; }
                }, 2000);
            }
        }

        // 3. PeerJS Logic (Unchanged mostly, but uses processedStream)
        function initPeer() {
            peer = new Peer(); 

            peer.on('open', (id) => {
                myIdInput.value = id;
                statusText.textContent = "Ready";
                statusText.classList.add('online');
            });

            peer.on('call', (call) => {
                if (confirm("Incoming call! Accept?")) {
                    // Answer with the PROCESSED stream (with filters)
                    call.answer(processedStream);
                    handleCall(call);
                }
            });
        }

        function makeCall() {
            const remoteId = document.getElementById('friend-id').value;
            if (!remoteId) return alert("Enter ID");
            statusText.textContent = "Calling...";
            // Call with PROCESSED stream
            const call = peer.call(remoteId, processedStream);
            handleCall(call);
        }

        function handleCall(call) {
            currentCall = call;
            document.getElementById('call-input-area').style.display = 'none';
            document.getElementById('end-btn').style.display = 'block';
            document.getElementById('connection-controls').style.display = 'none';
            statusText.textContent = "Connected";

            call.on('stream', (remoteStream) => {
                remoteVideo.srcObject = remoteStream;
            });

            call.on('close', () => endCallUI());
        }

        function endCall() {
            if (currentCall) currentCall.close();
            endCallUI();
        }

        function endCallUI() {
            remoteVideo.srcObject = null;
            document.getElementById('call-input-area').style.display = 'flex';
            document.getElementById('connection-controls').style.display = 'flex';
            document.getElementById('end-btn').style.display = 'none';
            statusText.textContent = "Call Ended";
        }

        // 4. Toggles (Mute/Video)
        // We must toggle the tracks on the RAW stream because that feeds the canvas
        function toggleAudio() {
            if (!localRawStream) return;
            const audioTrack = localRawStream.getAudioTracks()[0];
            audioTrack.enabled = !audioTrack.enabled;
            btnMic.classList.toggle('off', !audioTrack.enabled);
        }

        function toggleVideo() {
            if (!localRawStream) return;
            const videoTrack = localRawStream.getVideoTracks()[0];
            videoTrack.enabled = !videoTrack.enabled;
            btnCam.classList.toggle('off', !videoTrack.enabled);
        }

        function copyID() {
            myIdInput.select();
            document.execCommand("copy");
        }

        // Start
        startSystem();

    </script>
</body>
</html>